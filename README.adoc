= devops-stack-module-longhorn
// Document attributes to replace along the document
:longhorn-chart-version: 1.5.3
:original-repo-url: https://github.com/longhorn/longhorn

A https://devops-stack.io[DevOps Stack] module to deploy and configure https://longhorn.io/[Longhorn].

The Longhorn chart used by this module is shipped in this repository as well, in order to avoid any unwanted behaviors caused by unsupported versions. 

[cols="1,1,1",options="autowidth,header"]
|===
|Current Chart Version |Original Repository |Default Values
|*{longhorn-chart-version}* |{original-repo-url}/tree/master/chart[Chart] | https://artifacthub.io/packages/helm/longhorn/longhorn/{longhorn-chart-version}?modal=values[`values.yaml`]
|===

IMPORTANT: For the moment, this module only supports the deployment of Longhorn in SKS clusters.

== Usage

A simple declaration of the module would look like this:

[source,terraform]
----
module "longhorn" {
  source = "git::https://github.com/camptocamp/devops-stack-module-longhorn.git?ref=<RELEASE>"

  cluster_name     = module.sks.cluster_name
  base_domain      = module.sks.base_domain
  cluster_issuer   = local.cluster_issuer
  argocd_namespace = module.argocd_bootstrap.argocd_namespace

  dependency_ids = {
    argocd = module.argocd_bootstrap.id
  }
}
----

You can enable the ingress to the Longhorn Dashboard. In that case, you will need to enable the respective flag and pass along the required OIDC configuration:

[source,terraform]
----
module "longhorn" {
  source = "git::https://github.com/camptocamp/devops-stack-module-longhorn.git?ref=<RELEASE>"

  cluster_name     = module.sks.cluster_name
  base_domain      = module.sks.base_domain
  cluster_issuer   = local.cluster_issuer
  argocd_namespace = module.argocd_bootstrap.argocd_namespace

  enable_dashboard_ingress = true
  oidc                     = module.oidc.oidc

  dependency_ids = {
    argocd = module.argocd_bootstrap.id
    traefik      = module.traefik.id
    cert-manager = module.cert-manager.id
    keycloak     = module.keycloak.id
    oidc         = module.oidc.id
  }
----

NOTE: The previous example uses xref:keycloak:ROOT:README.adoc[Keycloak] as an OIDC provider, but you can use any other you want.

In case you want to backup the content of the persistent volumes, you have the possibility of enabling the backup feature. In that case, you will need to enable the respective flag and pass along the require S3 configuration:

[source,terraform]
----
module "longhorn" {
  source = "git::https://github.com/camptocamp/devops-stack-module-longhorn.git?ref=<RELEASE>"

  cluster_name     = module.sks.cluster_name
  base_domain      = module.sks.base_domain
  cluster_issuer   = local.cluster_issuer
  argocd_namespace = module.argocd_bootstrap.argocd_namespace

  enable_dashboard_ingress = true
  oidc                     = module.oidc.oidc

  enable_pv_backups = true
  backup_storage = {
    bucket_name = resource.aws_s3_bucket.this["longhorn"].id
    region      = resource.aws_s3_bucket.this["longhorn"].region
    endpoint    = "sos-${resource.aws_s3_bucket.this["longhorn"].region}.exo.io"
    access_key  = resource.exoscale_iam_access_key.s3_iam_key["longhorn"].key
    secret_key  = resource.exoscale_iam_access_key.s3_iam_key["longhorn"].secret
  }

  dependency_ids = {
    argocd = module.argocd_bootstrap.id
    traefik      = module.traefik.id
    cert-manager = module.cert-manager.id
    keycloak     = module.keycloak.id
    oidc         = module.oidc.id
  }
----


IMPORTANT: You are in charge of creating the S3 bucket to store the PV backups. We've decided to keep the creation of this bucket outside of this module, mainly because the persistence of the data should not be related to the instantiation of the module itself.

TIP: Check the SKS deployment example to see how to create the S3 bucket and to better understand the values passed on the example above.

TIP: On the technical reference below you will find further customization options, such as the backup/snapshot schedule.

If there is a need to configure something besides the common settings that we have provided, you can customize the chart's `values.yaml` by adding an Helm configuration as an HCL structure:

[source,terraform]
----
module "longhorn" {
  source = "git::https://github.com/camptocamp/devops-stack-module-longhorn.git?ref=<RELEASE>"

  cluster_name     = module.sks.cluster_name
  base_domain      = module.sks.base_domain
  cluster_issuer   = local.cluster_issuer
  argocd_namespace = module.argocd_bootstrap.argocd_namespace

  enable_dashboard_ingress = true
  oidc                     = module.oidc.oidc

  enable_pv_backups = true
  backup_storage = {
    bucket_name = resource.aws_s3_bucket.this["longhorn"].id
    region      = resource.aws_s3_bucket.this["longhorn"].region
    endpoint    = "sos-${resource.aws_s3_bucket.this["longhorn"].region}.exo.io"
    access_key  = resource.exoscale_iam_access_key.s3_iam_key["longhorn"].key
    secret_key  = resource.exoscale_iam_access_key.s3_iam_key["longhorn"].secret
  }

  helm_values = [{ # Note the curly brackets here
    longhorn = {
      map = {
        string = "string"
        bool   = true
      }
      sequence = [
        {
          key1 = "value1"
          key2 = "value2"
        },
        {
          key1 = "value1"
          key2 = "value2"
        },
      ]
      sequence2 = [
        "string1",
        "string2"
      ]
    }
  }]

  dependency_ids = {
    argocd       = module.argocd_bootstrap.id
    traefik      = module.traefik.id
    cert-manager = module.cert-manager.id
    keycloak     = module.keycloak.id
    oidc         = module.oidc.id
  }
----

=== OIDC

There is an OAuth2-Proxy container deployed along with the Longhorn dashboard. Consequently, the `oidc` variable is expected to have at least the Issuer URL, the Client ID, and the Client Secret.

You can pass these values by pointing an output from another module (as above), or by defining them explicitly:

[source,terraform]
----
module "longhorn" {
  ...
  oidc = {
    issuer_url    = "<URL>"
    client_id     = "<ID>"
    client_secret = "<SECRET>"
  }
  ...
}
----

=== Restoring volume backups

1. If your pod and his volume are still up, start by shuting down the pod (be careful to also stop the Deployment/StatefulSet) and delete the volume using the Longhorn Dashboard.
2. Go to the backup tab of Longhorn Dashboard and restore the desired volume backup. You must check the _Use Previous Name_ checkbox in order to keep the old volume name.
3. Next, go to the volume tab, select your newly restored volume and choose _Create PV/PVC_ option. Select _Use Previous PVC_ option and validate.
4. You can now restore your application, which should attach the restored volume automatically.

== Technical Reference

=== Dependencies

==== `module.argocd_bootstrap.id`

This module must be one of the first ones to be deployed, since other modules require Persistent Volumes. Consequently it needs to be deployed right after the module `argocd_bootstrap`. This is the only dependency that is not optional.

==== `module.traefik.id` and `module.cert-manager.id`

When enabling the ingress for the Longhorn Dashboard, you need to add Traefik and cert-manager as dependencies.

==== `module.keycloak.id` and `module.oidc.id`

When using Keycloak as an OIDC provider for the Longhorn Dashboard, you need to add Keycloak and the OIDC module as dependencies.

// BEGIN_TF_DOCS
=== Requirements

The following requirements are needed by this module:

- [[requirement_argocd]] <<requirement_argocd,argocd>> (>= 5)

- [[requirement_random]] <<requirement_random,random>> (>= 3)

- [[requirement_utils]] <<requirement_utils,utils>> (>= 1)

=== Providers

The following providers are used by this module:

- [[provider_random]] <<provider_random,random>> (>= 3)

- [[provider_utils]] <<provider_utils,utils>> (>= 1)

- [[provider_argocd]] <<provider_argocd,argocd>> (>= 5)

- [[provider_null]] <<provider_null,null>>

=== Resources

The following resources are used by this module:

- https://registry.terraform.io/providers/oboukili/argocd/latest/docs/resources/application[argocd_application.this] (resource)
- https://registry.terraform.io/providers/oboukili/argocd/latest/docs/resources/project[argocd_project.this] (resource)
- https://registry.terraform.io/providers/hashicorp/null/latest/docs/resources/resource[null_resource.dependencies] (resource)
- https://registry.terraform.io/providers/hashicorp/null/latest/docs/resources/resource[null_resource.this] (resource)
- https://registry.terraform.io/providers/random/latest/docs/resources/string[random_string.oauth2_cookie_secret] (resource)
- https://registry.terraform.io/providers/cloudposse/utils/latest/docs/data-sources/deep_merge_yaml[utils_deep_merge_yaml.values] (data source)

=== Optional Inputs

The following input variables are optional (have default values):

==== [[input_cluster_name]] <<input_cluster_name,cluster_name>>

Description: Name given to the cluster. Value used for naming some the resources created by the module.

Type: `string`

Default: `"cluster"`

==== [[input_base_domain]] <<input_base_domain,base_domain>>

Description: Base domain of the cluster. Value used for the ingress' URL of the application.

Type: `string`

Default: `null`

==== [[input_subdomain]] <<input_subdomain,subdomain>>

Description: Subdomain of the cluster. Value used for the ingress' URL of the application.

Type: `string`

Default: `"apps"`

==== [[input_cluster_issuer]] <<input_cluster_issuer,cluster_issuer>>

Description: SSL certificate issuer to use. Usually you would configure this value as `letsencrypt-staging` or `letsencrypt-prod` on your root `*.tf` files.

Type: `string`

Default: `"selfsigned-issuer"`

==== [[input_argocd_project]] <<input_argocd_project,argocd_project>>

Description: Name of the Argo CD AppProject where the Application should be created. If not set, the Application will be created in a new AppProject only for this Application.

Type: `string`

Default: `null`

==== [[input_argocd_labels]] <<input_argocd_labels,argocd_labels>>

Description: Labels to attach to the Argo CD Application resource.

Type: `map(string)`

Default: `{}`

==== [[input_destination_cluster]] <<input_destination_cluster,destination_cluster>>

Description: Destination cluster where the application should be deployed.

Type: `string`

Default: `"in-cluster"`

==== [[input_target_revision]] <<input_target_revision,target_revision>>

Description: Override of target revision of the application chart.

Type: `string`

Default: `"v3.3.0"`

==== [[input_helm_values]] <<input_helm_values,helm_values>>

Description: Helm chart value overrides. They should be passed as a list of HCL structures.

Type: `any`

Default: `[]`

==== [[input_app_autosync]] <<input_app_autosync,app_autosync>>

Description: Automated sync options for the Argo CD Application resource.

Type:
[source,hcl]
----
object({
    allow_empty = optional(bool)
    prune       = optional(bool)
    self_heal   = optional(bool)
  })
----

Default:
[source,json]
----
{
  "allow_empty": false,
  "prune": true,
  "self_heal": true
}
----

==== [[input_dependency_ids]] <<input_dependency_ids,dependency_ids>>

Description: IDs of the other modules on which this module depends on.

Type: `map(string)`

Default: `{}`

==== [[input_storage_over_provisioning_percentage]] <<input_storage_over_provisioning_percentage,storage_over_provisioning_percentage>>

Description: Set the storage over-provisioning percentage. **This values should be modified only when really needed.**

Type: `number`

Default: `100`

==== [[input_storage_minimal_available_percentage]] <<input_storage_minimal_available_percentage,storage_minimal_available_percentage>>

Description: Set the minimal available storage percentage. **This values should be modified only when really needed.** The default is 25%, as https://longhorn.io/docs/1.3.1/best-practices/#minimal-available-storage-and-over-provisioning[recommended in the best practices] for single-disk nodes.

Type: `number`

Default: `25`

==== [[input_enable_pv_backups]] <<input_enable_pv_backups,enable_pv_backups>>

Description: Boolean to enable backups of Longhorn volumes to an external object storage.

Type: `bool`

Default: `false`

==== [[input_set_default_storage_class]] <<input_set_default_storage_class,set_default_storage_class>>

Description: Boolean to set the Storage Class with the backup configuration as the default for all Persistent Volumes.

Type: `bool`

Default: `true`

==== [[input_backup_storage]] <<input_backup_storage,backup_storage>>

Description: Exoscale SOS bucket configuration where the backups will be stored. **This configuration is required if the variable `enable_pv_backups` is set to `true`.**

Type:
[source,hcl]
----
object({
    bucket_name = string
    region      = string
    endpoint    = string
    access_key  = string
    secret_key  = string
  })
----

Default: `null`

==== [[input_backup_configuration]] <<input_backup_configuration,backup_configuration>>

Description: The following values can be configured:
. `snapshot_enabled` - Enable Longhorn automatic snapshots.
. `snapshot_cron` - Cron schedule to configure Longhorn automatic snapshots.
. `snapshot_retention` - Retention of Longhorn automatic snapshots in days.
. `backup_enabled` - Enable Longhorn automatic backups to object storage.
. `backup_cron` - Cron schedule to configure Longhorn automatic backups.
. `backup_retention` - Retention of Longhorn automatic backups in days.

/!\ These settings cannot be changed after StorageClass creation without having to recreate it!

Type:
[source,hcl]
----
object({
    snapshot_enabled   = bool
    snapshot_cron      = string
    snapshot_retention = number
    backup_enabled     = bool
    backup_cron        = string
    backup_retention   = number
  })
----

Default:
[source,json]
----
{
  "backup_cron": "30 */12 * * *",
  "backup_enabled": false,
  "backup_retention": "2",
  "snapshot_cron": "0 */2 * * *",
  "snapshot_enabled": false,
  "snapshot_retention": "1"
}
----

==== [[input_enable_preupgrade_check]] <<input_enable_preupgrade_check,enable_preupgrade_check>>

Description: Boolean to enable the pre-upgrade check. Usually this value should be set to `true` and only set to `false` if you are bootstrapping a new cluster, otherwise the first deployment will not work.

Type: `bool`

Default: `true`

==== [[input_enable_service_monitor]] <<input_enable_service_monitor,enable_service_monitor>>

Description: Boolean to enable the deployment of a service monitor.

Type: `bool`

Default: `false`

==== [[input_additional_alert_labels]] <<input_additional_alert_labels,additional_alert_labels>>

Description: Additional labels to add to Longhorn alerts.

Type: `map(string)`

Default: `{}`

==== [[input_enable_dashboard_ingress]] <<input_enable_dashboard_ingress,enable_dashboard_ingress>>

Description: Boolean to enable the creation of an ingress for the Longhorn's dashboard. **If enabled, you must provide a value for `base_domain`.**

Type: `bool`

Default: `false`

==== [[input_enable_monitoring_dashboard]] <<input_enable_monitoring_dashboard,enable_monitoring_dashboard>>

Description: Boolean to enable the provisioning of a Longhorn dashboard for Grafana.

Type: `bool`

Default: `true`

==== [[input_oidc]] <<input_oidc,oidc>>

Description: OIDC settings to configure OAuth2-Proxy which will be used to protect Longhorn's dashboard.

Type:
[source,hcl]
----
object({
    issuer_url              = string
    oauth_url               = optional(string, "")
    token_url               = optional(string, "")
    api_url                 = optional(string, "")
    client_id               = string
    client_secret           = string
    oauth2_proxy_extra_args = optional(list(string), [])
  })
----

Default: `null`

==== [[input_automatic_filesystem_trim]] <<input_automatic_filesystem_trim,automatic_filesystem_trim>>

Description: Settings to enable and configure automatic filesystem trim of volumes managed by Longhorn.

Type:
[source,hcl]
----
object({
    enabled   = bool
    cron      = string
    job_group = string
  })
----

Default:
[source,json]
----
{
  "cron": "0 6 * * *",
  "enabled": false,
  "job_group": ""
}
----

==== [[input_recurring_job_selectors]] <<input_recurring_job_selectors,recurring_job_selectors>>

Description: Define a group list to add to recurring job selector for the default storage class (the custom backup one if `set_default_storage_class` is set or else the Longhorn default one).

Type:
[source,hcl]
----
list(object({
    name    = string
    isGroup = bool
  }))
----

Default: `null`

==== [[input_replica_count]] <<input_replica_count,replica_count>>

Description: Amount of replicas created by Longhorn for each volume.

Type: `number`

Default: `2`

==== [[input_tolerations]] <<input_tolerations,tolerations>>

Description: Tolerations to be added to the core Longhorn components that manage storage on nodes. **These tolerations are required if you want Longhorn to schedule storage on nodes that are tainted.**

These settings only have an effect on the first deployment. If added at a later time, you need to also add them on the _Settings_ tab in the Longhorn Dashboard. Check the https://longhorn.io/docs/latest/advanced-resources/deploy/taint-toleration/[official documentation] for more detailed information.

**Only tolerations with the "Equal" operator are supported**, because the Longhorn Helm chart expects a parsed list as a string in the `defaultSettings.taintToleration` value.

Type:
[source,hcl]
----
list(object({
    key      = string
    operator = string
    value    = string
    effect   = string
  }))
----

Default: `[]`

=== Outputs

The following outputs are exported:

==== [[output_id]] <<output_id,id>>

Description: ID to pass other modules in order to refer to this module as a dependency.
// END_TF_DOCS

=== Reference in table format 

.Show tables
[%collapsible]
====
// BEGIN_TF_TABLES
= Requirements

[cols="a,a",options="header,autowidth"]
|===
|Name |Version
|[[requirement_argocd]] <<requirement_argocd,argocd>> |>= 5
|[[requirement_random]] <<requirement_random,random>> |>= 3
|[[requirement_utils]] <<requirement_utils,utils>> |>= 1
|===

= Providers

[cols="a,a",options="header,autowidth"]
|===
|Name |Version
|[[provider_random]] <<provider_random,random>> |>= 3
|[[provider_null]] <<provider_null,null>> |n/a
|[[provider_utils]] <<provider_utils,utils>> |>= 1
|[[provider_argocd]] <<provider_argocd,argocd>> |>= 5
|===

= Resources

[cols="a,a",options="header,autowidth"]
|===
|Name |Type
|https://registry.terraform.io/providers/oboukili/argocd/latest/docs/resources/application[argocd_application.this] |resource
|https://registry.terraform.io/providers/oboukili/argocd/latest/docs/resources/project[argocd_project.this] |resource
|https://registry.terraform.io/providers/hashicorp/null/latest/docs/resources/resource[null_resource.dependencies] |resource
|https://registry.terraform.io/providers/hashicorp/null/latest/docs/resources/resource[null_resource.this] |resource
|https://registry.terraform.io/providers/random/latest/docs/resources/string[random_string.oauth2_cookie_secret] |resource
|https://registry.terraform.io/providers/cloudposse/utils/latest/docs/data-sources/deep_merge_yaml[utils_deep_merge_yaml.values] |data source
|===

= Inputs

[cols="a,a,a,a,a",options="header,autowidth"]
|===
|Name |Description |Type |Default |Required
|[[input_cluster_name]] <<input_cluster_name,cluster_name>>
|Name given to the cluster. Value used for naming some the resources created by the module.
|`string`
|`"cluster"`
|no

|[[input_base_domain]] <<input_base_domain,base_domain>>
|Base domain of the cluster. Value used for the ingress' URL of the application.
|`string`
|`null`
|no

|[[input_subdomain]] <<input_subdomain,subdomain>>
|Subdomain of the cluster. Value used for the ingress' URL of the application.
|`string`
|`"apps"`
|no

|[[input_cluster_issuer]] <<input_cluster_issuer,cluster_issuer>>
|SSL certificate issuer to use. Usually you would configure this value as `letsencrypt-staging` or `letsencrypt-prod` on your root `*.tf` files.
|`string`
|`"selfsigned-issuer"`
|no

|[[input_argocd_project]] <<input_argocd_project,argocd_project>>
|Name of the Argo CD AppProject where the Application should be created. If not set, the Application will be created in a new AppProject only for this Application.
|`string`
|`null`
|no

|[[input_argocd_labels]] <<input_argocd_labels,argocd_labels>>
|Labels to attach to the Argo CD Application resource.
|`map(string)`
|`{}`
|no

|[[input_destination_cluster]] <<input_destination_cluster,destination_cluster>>
|Destination cluster where the application should be deployed.
|`string`
|`"in-cluster"`
|no

|[[input_target_revision]] <<input_target_revision,target_revision>>
|Override of target revision of the application chart.
|`string`
|`"v3.3.0"`
|no

|[[input_helm_values]] <<input_helm_values,helm_values>>
|Helm chart value overrides. They should be passed as a list of HCL structures.
|`any`
|`[]`
|no

|[[input_app_autosync]] <<input_app_autosync,app_autosync>>
|Automated sync options for the Argo CD Application resource.
|

[source]
----
object({
    allow_empty = optional(bool)
    prune       = optional(bool)
    self_heal   = optional(bool)
  })
----

|

[source]
----
{
  "allow_empty": false,
  "prune": true,
  "self_heal": true
}
----

|no

|[[input_dependency_ids]] <<input_dependency_ids,dependency_ids>>
|IDs of the other modules on which this module depends on.
|`map(string)`
|`{}`
|no

|[[input_storage_over_provisioning_percentage]] <<input_storage_over_provisioning_percentage,storage_over_provisioning_percentage>>
|Set the storage over-provisioning percentage. **This values should be modified only when really needed.**
|`number`
|`100`
|no

|[[input_storage_minimal_available_percentage]] <<input_storage_minimal_available_percentage,storage_minimal_available_percentage>>
|Set the minimal available storage percentage. **This values should be modified only when really needed.** The default is 25%, as https://longhorn.io/docs/1.3.1/best-practices/#minimal-available-storage-and-over-provisioning[recommended in the best practices] for single-disk nodes.
|`number`
|`25`
|no

|[[input_enable_pv_backups]] <<input_enable_pv_backups,enable_pv_backups>>
|Boolean to enable backups of Longhorn volumes to an external object storage.
|`bool`
|`false`
|no

|[[input_set_default_storage_class]] <<input_set_default_storage_class,set_default_storage_class>>
|Boolean to set the Storage Class with the backup configuration as the default for all Persistent Volumes.
|`bool`
|`true`
|no

|[[input_backup_storage]] <<input_backup_storage,backup_storage>>
|Exoscale SOS bucket configuration where the backups will be stored. **This configuration is required if the variable `enable_pv_backups` is set to `true`.**
|

[source]
----
object({
    bucket_name = string
    region      = string
    endpoint    = string
    access_key  = string
    secret_key  = string
  })
----

|`null`
|no

|[[input_backup_configuration]] <<input_backup_configuration,backup_configuration>>
|The following values can be configured:
. `snapshot_enabled` - Enable Longhorn automatic snapshots.
. `snapshot_cron` - Cron schedule to configure Longhorn automatic snapshots.
. `snapshot_retention` - Retention of Longhorn automatic snapshots in days.
. `backup_enabled` - Enable Longhorn automatic backups to object storage.
. `backup_cron` - Cron schedule to configure Longhorn automatic backups.
. `backup_retention` - Retention of Longhorn automatic backups in days.

/!\ These settings cannot be changed after StorageClass creation without having to recreate it!

|

[source]
----
object({
    snapshot_enabled   = bool
    snapshot_cron      = string
    snapshot_retention = number
    backup_enabled     = bool
    backup_cron        = string
    backup_retention   = number
  })
----

|

[source]
----
{
  "backup_cron": "30 */12 * * *",
  "backup_enabled": false,
  "backup_retention": "2",
  "snapshot_cron": "0 */2 * * *",
  "snapshot_enabled": false,
  "snapshot_retention": "1"
}
----

|no

|[[input_enable_preupgrade_check]] <<input_enable_preupgrade_check,enable_preupgrade_check>>
|Boolean to enable the pre-upgrade check. Usually this value should be set to `true` and only set to `false` if you are bootstrapping a new cluster, otherwise the first deployment will not work.
|`bool`
|`true`
|no

|[[input_enable_service_monitor]] <<input_enable_service_monitor,enable_service_monitor>>
|Boolean to enable the deployment of a service monitor.
|`bool`
|`false`
|no

|[[input_additional_alert_labels]] <<input_additional_alert_labels,additional_alert_labels>>
|Additional labels to add to Longhorn alerts.
|`map(string)`
|`{}`
|no

|[[input_enable_dashboard_ingress]] <<input_enable_dashboard_ingress,enable_dashboard_ingress>>
|Boolean to enable the creation of an ingress for the Longhorn's dashboard. **If enabled, you must provide a value for `base_domain`.**
|`bool`
|`false`
|no

|[[input_enable_monitoring_dashboard]] <<input_enable_monitoring_dashboard,enable_monitoring_dashboard>>
|Boolean to enable the provisioning of a Longhorn dashboard for Grafana.
|`bool`
|`true`
|no

|[[input_oidc]] <<input_oidc,oidc>>
|OIDC settings to configure OAuth2-Proxy which will be used to protect Longhorn's dashboard.
|

[source]
----
object({
    issuer_url              = string
    oauth_url               = optional(string, "")
    token_url               = optional(string, "")
    api_url                 = optional(string, "")
    client_id               = string
    client_secret           = string
    oauth2_proxy_extra_args = optional(list(string), [])
  })
----

|`null`
|no

|[[input_automatic_filesystem_trim]] <<input_automatic_filesystem_trim,automatic_filesystem_trim>>
|Settings to enable and configure automatic filesystem trim of volumes managed by Longhorn.
|

[source]
----
object({
    enabled   = bool
    cron      = string
    job_group = string
  })
----

|

[source]
----
{
  "cron": "0 6 * * *",
  "enabled": false,
  "job_group": ""
}
----

|no

|[[input_recurring_job_selectors]] <<input_recurring_job_selectors,recurring_job_selectors>>
|Define a group list to add to recurring job selector for the default storage class (the custom backup one if `set_default_storage_class` is set or else the Longhorn default one).
|

[source]
----
list(object({
    name    = string
    isGroup = bool
  }))
----

|`null`
|no

|[[input_replica_count]] <<input_replica_count,replica_count>>
|Amount of replicas created by Longhorn for each volume.
|`number`
|`2`
|no

|[[input_tolerations]] <<input_tolerations,tolerations>>
|Tolerations to be added to the core Longhorn components that manage storage on nodes. **These tolerations are required if you want Longhorn to schedule storage on nodes that are tainted.**

These settings only have an effect on the first deployment. If added at a later time, you need to also add them on the _Settings_ tab in the Longhorn Dashboard. Check the https://longhorn.io/docs/latest/advanced-resources/deploy/taint-toleration/[official documentation] for more detailed information.

**Only tolerations with the "Equal" operator are supported**, because the Longhorn Helm chart expects a parsed list as a string in the `defaultSettings.taintToleration` value.

|

[source]
----
list(object({
    key      = string
    operator = string
    value    = string
    effect   = string
  }))
----

|`[]`
|no

|===

= Outputs

[cols="a,a",options="header,autowidth"]
|===
|Name |Description
|[[output_id]] <<output_id,id>> |ID to pass other modules in order to refer to this module as a dependency.
|===
// END_TF_TABLES
====
